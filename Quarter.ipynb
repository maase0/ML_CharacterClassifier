{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.8 64-bit ('venv')",
   "metadata": {
    "interpreter": {
     "hash": "fc6a171883505f6cf52af31efce977f648d52d3a8750cfd6622a125905379d6c"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "Imports"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from collections import Counter\n",
    "import random\n",
    "\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Change matplotlib to use a Japanese font\n",
    "# to actually be able to display correctly\n",
    "matplotlib.rcParams.update(\n",
    "    {\n",
    "        'text.usetex': False,\n",
    "        'font.family': 'MS Gothic'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "source": [
    "Global variables"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug = False\n",
    "num_chars = 100"
   ]
  },
  {
   "source": [
    "Load data, print some for verification"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = joblib.load(f'{base_name}_{width}x{width}px.pkl.part1')\n",
    "data = joblib.load('./Input/all_characters_64x64px.pkl.part1')\n",
    "\n",
    "if debug:\n",
    "    print('Number of samples: ', len(data['data']))\n",
    "    print('keys: ', list(data.keys()))\n",
    "    print('description: ', data['description'])\n",
    "    print('image shape: ', data['data'][0].shape)\n",
    "    print('labels:', np.unique(data['label']))\n",
    "\n",
    "    #Counter(data['label'])\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(10,10))\n",
    "    for i in range(25):\n",
    "        index = random.randint(0, len(data['data']) - 1)\n",
    "        plt.subplot(5,5,i+1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        plt.imshow(data['data'][index], cmap=plt.cm.binary)\n",
    "        # The CIFAR labels happen to be arrays, \n",
    "        # which is why you need the extra index\n",
    "        plt.xlabel(data['label'][index])\n",
    "    plt.show()\n"
   ]
  },
  {
   "source": [
    "Split data into training and test"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#X = np.array(data['data'])\n",
    "#y = np.array(data['label'])\n",
    "\n",
    "n_samples = len(data['data'])\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    np.array(data['data'][:num_chars*200]),\n",
    "    np.array(data['label'][:num_chars*200]),\n",
    "    test_size=0.4,\n",
    "    shuffle=True,\n",
    "    random_state=42)\n",
    "\n",
    "del data\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], 64, 64, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 64, 64, 1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "source": [
    "Change labels from strings to numbers so tensorflow can use them"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.fit_transform(y_test)"
   ]
  },
  {
   "source": [
    "Create the model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "#model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "#model.add(layers.MaxPooling2D((2, 2)))\n",
    "#model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "model.add(layers.Dense(4096, activation='relu'))\n",
    "model.add(layers.Dense(4096, activation='relu'))\n",
    "#model.add(layers.Dense(4096, activation='relu'))\n",
    "#model.add(layers.Dense(4096, activation='relu'))\n",
    "model.add(layers.Dense(2048, activation='relu'))\n",
    "model.add(layers.Dense(2048, activation='relu'))\n",
    "\n",
    "model.add(layers.Dense(759))\n",
    "\n",
    "if debug:\n",
    "    model.summary()"
   ]
  },
  {
   "source": [
    "Train the model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=30, \n",
    "                    validation_data=(X_test, y_test))"
   ]
  },
  {
   "source": [
    "Display model information"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "test_loss, test_acc = model.evaluate(X_test,  y_test, verbose=2)\n",
    "\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.argmax(model.predict(X_test), axis=1)\n",
    "y_true = y_test\n",
    " \n",
    "#y_pred = le.inverse_transform(y_pred)\n",
    "#y_true = le.inverse_transform(y_test)\n",
    "\n",
    "labels = np.unique(le.inverse_transform(y_test))\n",
    "print(labels)\n",
    "\n",
    "conf_mtx = tf.math.confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(100, 80))\n",
    "sns.heatmap(conf_mtx, xticklabels=labels, yticklabels=labels, \n",
    "            annot=True, fmt='g')\n",
    "plt.xlabel('Prediction')\n",
    "plt.ylabel('Label')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}